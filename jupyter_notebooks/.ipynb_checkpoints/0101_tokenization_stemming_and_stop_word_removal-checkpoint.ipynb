{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing data: tokenization, stemming, and removal of stop words\n",
    "\n",
    "\n",
    "Here we will look at three common pre-processing step sin natural language processing:\n",
    "\n",
    "1) Tokenization: the process of segmenting text into words, clauses or sentences (here we will separate out words and remove punctuation).\n",
    "\n",
    "2) Stemming: reducing related words to a common stem.\n",
    "\n",
    "3) Removal of stop words: removal of commonly used words unlikely to be useful for learning.\n",
    "\n",
    "We will load up 50,000 examples from the movie review database, imdb, and use the NLTK library for text pre-processing. The NLTK library comes with a standard Anaconda Python installation (www.anaconda.com), but we will need to use it to install the ‘stopwords’ corpus of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the NLTK library\n",
    "\n",
    "This command will open the NLTK downloader. You may download everything from the collections tab. Otherwise, for this example you may just download 'stopwords' from the 'Corpora' tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/michael/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# To open dialog download:\n",
    "# nltk.download(); \n",
    "\n",
    "# To downlaod just stopwords:\n",
    "nltk.download('stopwords');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "If you have not previously loaded and saved the imdb data, run the following which will load the file from the internet and save it locally to the same location this is code is run from.\n",
    "\n",
    "We will load data into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_location = 'https://gitlab.com/michaelallen1966/00_python_snippets' +\\\n",
    "    '_and_recipes/raw/master/machine_learning/data/IMDb.csv'\n",
    "imdb = pd.read_csv(file_location)\n",
    "# save to current directory\n",
    "imdb.to_csv('imdb.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already saved the data locally, load it up into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "imdb = pd.read_csv('imdb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what columns exist in the imdb data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['review', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "print (list(imdb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll pull out the first review and sentiment to look at the contents. The review is text and the sentiment label is either 0 (negative) or 1 (positive) based on how the reviewer rated it on imdb. We will use the Pnadas DataFrame .iloc method to selc the first review (which has an index of zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have no read the novel on which \"The Kite Runner\" is based. My wife and daughter, who did, thought the movie fell a long way short of the book, and I'm prepared to take their word for it. But, on its own, the movie is good -- not great but good. How accurately does it portray the havoc created by the Soviet invasion of Afghanistan? How convincingly does it show the intolerant Taliban regime that followed? I'd rate it C+ on the first and B+ on the second. The human story, the Afghan-American who returned to the country to rescue the son of his childhood playmate, is well done but it is on this count particularly that I'm told the book was far more convincing than the movie. The most exciting part of the film, however -- the kite contests in Kabul and, later, a mini-contest in California -- cannot have been equaled by the book. I'd wager money on that.\n"
     ]
    }
   ],
   "source": [
    "print(imdb['review'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(imdb['sentiment'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to lower case\n",
    "\n",
    "We don't want words being trested differently dut to differences in upper and lower case, so we'll ocnvert all reviews to lower case, an dlook at the first review again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have no read the novel on which \"the kite runner\" is based. my wife and daughter, who did, thought the movie fell a long way short of the book, and i'm prepared to take their word for it. but, on its own, the movie is good -- not great but good. how accurately does it portray the havoc created by the soviet invasion of afghanistan? how convincingly does it show the intolerant taliban regime that followed? i'd rate it c+ on the first and b+ on the second. the human story, the afghan-american who returned to the country to rescue the son of his childhood playmate, is well done but it is on this count particularly that i'm told the book was far more convincing than the movie. the most exciting part of the film, however -- the kite contests in kabul and, later, a mini-contest in california -- cannot have been equaled by the book. i'd wager money on that.\n"
     ]
    }
   ],
   "source": [
    "imdb['review'] = imdb['review'].str.lower()\n",
    "print(imdb['review'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "We will use word_tokenize method from NLTK to split the review text into individual words (and you will see that punctuation is also produced as separate 'words').\n",
    "Let's look at our example row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'have', 'no', 'read', 'the', 'novel', 'on', 'which', '``', 'the', 'kite', 'runner', \"''\", 'is', 'based', '.', 'my', 'wife', 'and', 'daughter', ',', 'who', 'did', ',', 'thought', 'the', 'movie', 'fell', 'a', 'long', 'way', 'short', 'of', 'the', 'book', ',', 'and', 'i', \"'m\", 'prepared', 'to', 'take', 'their', 'word', 'for', 'it', '.', 'but', ',', 'on', 'its', 'own', ',', 'the', 'movie', 'is', 'good', '--', 'not', 'great', 'but', 'good', '.', 'how', 'accurately', 'does', 'it', 'portray', 'the', 'havoc', 'created', 'by', 'the', 'soviet', 'invasion', 'of', 'afghanistan', '?', 'how', 'convincingly', 'does', 'it', 'show', 'the', 'intolerant', 'taliban', 'regime', 'that', 'followed', '?', 'i', \"'d\", 'rate', 'it', 'c+', 'on', 'the', 'first', 'and', 'b+', 'on', 'the', 'second', '.', 'the', 'human', 'story', ',', 'the', 'afghan-american', 'who', 'returned', 'to', 'the', 'country', 'to', 'rescue', 'the', 'son', 'of', 'his', 'childhood', 'playmate', ',', 'is', 'well', 'done', 'but', 'it', 'is', 'on', 'this', 'count', 'particularly', 'that', 'i', \"'m\", 'told', 'the', 'book', 'was', 'far', 'more', 'convincing', 'than', 'the', 'movie', '.', 'the', 'most', 'exciting', 'part', 'of', 'the', 'film', ',', 'however', '--', 'the', 'kite', 'contests', 'in', 'kabul', 'and', ',', 'later', ',', 'a', 'mini-contest', 'in', 'california', '--', 'can', 'not', 'have', 'been', 'equaled', 'by', 'the', 'book', '.', 'i', \"'d\", 'wager', 'money', 'on', 'that', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print (nltk.word_tokenize(imdb['review'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now apply the word_tokenize to all records, making a new column in our imdb DataFrame. Each entry will be a list of words. Here we will also strip out non alphanumeric words/characters (such as numbers and punctuation) using .isalpha (you could use .isalnum if you wanted to keep in numbers as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_tokens(row):\n",
    "    review = row['review']\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    # taken only words (not punctuation)\n",
    "    token_words = [w for w in tokens if w.isalpha()]\n",
    "    return token_words\n",
    "\n",
    "imdb['words'] = imdb.apply(identify_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "Stemming reduces related words to a common stem. It is an optional process step, and it it is useful to test accuracy with and without stemming. Let's look at an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frighten', 'frighten', 'frighten']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "\n",
    "my_list = ['frightening', 'frightened', 'frightens']\n",
    "\n",
    "# Using a Python list comprehension method to apply to all words in my_list\n",
    "\n",
    "print ([stemming.stem(word) for word in my_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply this to all rows in our imdb DataFrame we will again define a function and apply it to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_list(row):\n",
    "    my_list = row['words']\n",
    "    stemmed_list = [stemming.stem(word) for word in my_list]\n",
    "    return (stemmed_list)\n",
    "\n",
    "imdb['stemmed_words'] = imdb.apply(stem_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check our stemmed words (using pandas DataFrame .iloc method to select the first row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'have', 'no', 'read', 'the', 'novel', 'on', 'which', 'the', 'kite', 'runner', 'is', 'base', 'my', 'wife', 'and', 'daughter', 'who', 'did', 'thought', 'the', 'movi', 'fell', 'a', 'long', 'way', 'short', 'of', 'the', 'book', 'and', 'i', 'prepar', 'to', 'take', 'their', 'word', 'for', 'it', 'but', 'on', 'it', 'own', 'the', 'movi', 'is', 'good', 'not', 'great', 'but', 'good', 'how', 'accur', 'doe', 'it', 'portray', 'the', 'havoc', 'creat', 'by', 'the', 'soviet', 'invas', 'of', 'afghanistan', 'how', 'convincingli', 'doe', 'it', 'show', 'the', 'intoler', 'taliban', 'regim', 'that', 'follow', 'i', 'rate', 'it', 'on', 'the', 'first', 'and', 'on', 'the', 'second', 'the', 'human', 'stori', 'the', 'who', 'return', 'to', 'the', 'countri', 'to', 'rescu', 'the', 'son', 'of', 'hi', 'childhood', 'playmat', 'is', 'well', 'done', 'but', 'it', 'is', 'on', 'thi', 'count', 'particularli', 'that', 'i', 'told', 'the', 'book', 'wa', 'far', 'more', 'convinc', 'than', 'the', 'movi', 'the', 'most', 'excit', 'part', 'of', 'the', 'film', 'howev', 'the', 'kite', 'contest', 'in', 'kabul', 'and', 'later', 'a', 'in', 'california', 'can', 'not', 'have', 'been', 'equal', 'by', 'the', 'book', 'i', 'wager', 'money', 'on', 'that']\n"
     ]
    }
   ],
   "source": [
    "print(imdb['stemmed_words'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Stop words' are commonly used words that are unlikely to have any benefit in natural language processing. These includes words such as 'a', 'the', 'is'. \n",
    "\n",
    "As before we will define a function and apply it to our DataFrame.\n",
    "\n",
    "We create a set of words that we will call 'stops' (using a set helps to speed up removing stop words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words(\"english\"))                  \n",
    "\n",
    "def remove_stops(row):\n",
    "    my_list = row['stemmed_words']\n",
    "    meaningful_words = [w for w in my_list if not w in stops]\n",
    "    return (meaningful_words)\n",
    "\n",
    "imdb['stem_meaningful'] = imdb.apply(remove_stops, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the stemmed words, without stop words, from the first record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['read', 'novel', 'kite', 'runner', 'base', 'wife', 'daughter', 'thought', 'movi', 'fell', 'long', 'way', 'short', 'book', 'prepar', 'take', 'word', 'movi', 'good', 'great', 'good', 'accur', 'doe', 'portray', 'havoc', 'creat', 'soviet', 'invas', 'afghanistan', 'convincingli', 'doe', 'show', 'intoler', 'taliban', 'regim', 'follow', 'rate', 'first', 'second', 'human', 'stori', 'return', 'countri', 'rescu', 'son', 'hi', 'childhood', 'playmat', 'well', 'done', 'thi', 'count', 'particularli', 'told', 'book', 'wa', 'far', 'convinc', 'movi', 'excit', 'part', 'film', 'howev', 'kite', 'contest', 'kabul', 'later', 'california', 'equal', 'book', 'wager', 'money']\n"
     ]
    }
   ],
   "source": [
    "print(imdb['stem_meaningful'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejoin meaningful stemmed words\n",
    "\n",
    "Now we will rejoin our meaningful stemmed words into a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejoin_words(row):\n",
    "    my_list = row['stem_meaningful']\n",
    "    joined_words = ( \" \".join(my_list))\n",
    "    return joined_words\n",
    "\n",
    "imdb['processed'] = imdb.apply(rejoin_words, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save processed data\n",
    "\n",
    "Now we'll save our processed data as a csv. We'll drop the intermediate columns in our Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['review', 'sentiment', 'words', 'stemmed_words', 'stem_meaningful', 'processed']\n"
     ]
    }
   ],
   "source": [
    "print(list(imdb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['review', 'words', 'stemmed_words', 'stem_meaningful']\n",
    "imdb.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.to_csv('imdb_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
