{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning introduction\n",
    "\n",
    "### RL involves:\n",
    "* Trial and error search\n",
    "* Receiving and maximising reward (often delayed)\n",
    "* Linking state -> action -> reward\n",
    "* Must be able to sense something of their environment\n",
    "* Involves uncertainty in sensing and linking action to reward\n",
    "* Learning -> improved choice of actions over time\n",
    "* All models find a way to balance best predicted action vs. exploration\n",
    "\n",
    "### Elements of RL\n",
    "* *Environment*: all observable and unobservable information relevant to us\n",
    "* *Observation*: sensing the environment\n",
    "* *State*: the perceived (or perceivable) environment \n",
    "* *Agent*: senses environment, decides on action, receives and monitors rewards\n",
    "* *Action*: may be discrete (e.g. turn left) or continuous (accelerator pedal)\n",
    "* *Policy* (how to link state to action; often based on probabilities)\n",
    "* *Reward signal*: aim is to accumulate maximum reward over time\n",
    "* *Value function* of a state: prediction of likely/possible long-term reward\n",
    "* *Q*: prediction of likely/possible long-term reward of an *action*\n",
    "* *Model* (optional): a simulation of the environment\n",
    "\n",
    "### Types of model\n",
    "\n",
    "* *Model-based*: have model of environment (e.g. a board game)\n",
    "* *Model-free*: used when environment not fully known\n",
    "* *Policy-based*: identify best policy directly\n",
    "* *Value-based*: estimate value of a decision\n",
    "* *Off-policy*: can learn from historic data from other agent\n",
    "* *On-policy*: requires active learning from current decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "AI-gym: `pip install gym gym[atari]`\n",
    "\n",
    "PyTorch: see https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Gym\n",
    "\n",
    "Gym (from OpenAI: https://openai.com/) is a toolkit for developing and comparing reinforcement learning algorithms. It supports teaching agents everything from walking to playing games like Pong or Pinball.\n",
    "\n",
    "https://gym.openai.com/\n",
    "\n",
    "AI gym has a standard interface. An action is transfered with step, and this returns:\n",
    "\n",
    "* *obs*: New observation\n",
    "* *reward*: reward from action\n",
    "* *done*: 'True' if game over\n",
    "* *info*: A dictionary of extra information (game dependent)\n",
    "\n",
    "The syntax is:\n",
    "\n",
    "`obs, reward, done, info = env.step(action)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "*Cross entropy* in neural nets provides probabilities across any number of classifications.\n",
    "\n",
    "*Cross entropy* RL is a model-free policy-based (on-policy) method. It is based on learning from previous best runs. For each observation the nn provides a probability of action to be taken. Use of sampling and probability allows exploration.\n",
    "\n",
    "Method steps:\n",
    "\n",
    "* Play n episodes using current model and environment\n",
    "* Calculate total reward for each episode\n",
    "* Keep best episodes (e.g. top 30%-50%)\n",
    "* Train on best episodes using observations and actions taken\n",
    "* Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpy_envs.env_simple_hospital_bed_1 import HospGym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY_GAME = False\n",
    "LEARNING_RATE = 0.003\n",
    "# Simulation duration\n",
    "SIM_DURATION = 365\n",
    "# Time step between actions\n",
    "TIME_STEP = 1.0\n",
    "# Number of episodes to train for\n",
    "TRAINING_EPISODES = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cross-entropy neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch neural net using the flexible pytorch nn.Modlule class.\n",
    "    Note: the neural net output is linear. To convert these to probabilities for\n",
    "    each action (sum to 1.0) a SoftMax activation on the final output is \n",
    "    required, but this is applied outside of the net itself, which improves\n",
    "    speed and stability of training.\n",
    "    \n",
    "    Layers in model:\n",
    "    * Input layer (implied, takes the number of observations)\n",
    "    * 48 node layer\n",
    "    * ReLU activation\n",
    "    * 24 node layer\n",
    "    * ReLU activation\n",
    "    * Output layer (size = number of possible actions)\n",
    "    \n",
    "    (A SoftMax layer will be added later)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, observation_space, action_space):\n",
    "        \"\"\"Define layers of sequential net\"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(observation_space, 48),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(48, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, action_space)\n",
    "    )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Define forward pass (simple, as using a pre-defined sequential\n",
    "        model)\"\"\"\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to play a single episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episode(sim, model, observation_space):\n",
    "    \"\"\"Play an episode\"\"\"\n",
    "    \n",
    "    # Define softmax layer\n",
    "    sm = nn.Softmax(dim=1) \n",
    "    \n",
    "    # Reset trackers and environment\n",
    "    episode_reward = 0\n",
    "    obs_tracker = []\n",
    "    action_tracker = []\n",
    "    \n",
    "    # Reset environment (returns first observation)\n",
    "    obs = sim.reset()\n",
    "    \n",
    "    # Start time counter for steps in simulation\n",
    "    next_stop = 0\n",
    "        \n",
    "    \n",
    "    # Continue loop until episode complete\n",
    "    while True: \n",
    "        \n",
    "        # Show game step (will slow game, but useful to watch at least once)\n",
    "        if DISPLAY_GAME:\n",
    "            sim.render()\n",
    "            \n",
    "        # Track observations\n",
    "        obs = np.float32(obs)\n",
    "        obs_tracker.append(obs)\n",
    "        \n",
    "        # Get action probability (put obs in Tensor first)\n",
    "        obs = torch.FloatTensor([obs])\n",
    "        act_probs = model(obs)\n",
    "        act_probs = sm(act_probs)\n",
    "        act_probs = act_probs.data.numpy()[0]\n",
    "        \n",
    "        # Get and track action: action sampled based on probability distribution\n",
    "        action = np.random.choice(len(act_probs), p=act_probs)\n",
    "        action_tracker.append(action)\n",
    "        \n",
    "        # Take action\n",
    "        obs, reward, done, info = sim.step(action)\n",
    "        episode_reward += reward\n",
    "        \n",
    "        # Advance simulation ready for next action\n",
    "        if not done:\n",
    "            next_stop += TIME_STEP\n",
    "            sim.env.run(until=next_stop)\n",
    "        \n",
    "        # Break loop if terminal state reached\n",
    "        if done:\n",
    "            break\n",
    "     \n",
    "    # Put results in dictionary\n",
    "    results = {'episode_reward': episode_reward,\n",
    "               'episode_obs': obs_tracker,\n",
    "               'episode_actions': action_tracker}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to filter best episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_episodes(results, percentile_cutoff = 70):\n",
    "    \"\"\"Get best episodes\"\"\"\n",
    "    \n",
    "    # Get episode rewards & define cuttoff\n",
    "    episode_rewards = [episode['episode_reward'] for episode in results]\n",
    "    reward_cutoff = np.percentile(episode_rewards, percentile_cutoff)\n",
    "    \n",
    "    # Get best episode observations and actions\n",
    "    obs = [episode['episode_obs'] for episode in results if \n",
    "           episode['episode_reward'] >= reward_cutoff]\n",
    "    \n",
    "    actions = [episode['episode_actions'] for episode in results if \n",
    "               episode['episode_reward'] >= reward_cutoff]\n",
    "    \n",
    "\n",
    "    # Convert list of observation arrays into a numpy array\n",
    "    obs = np.vstack(obs)\n",
    "    \n",
    "    # Flatten actions list and convert to NumPy\n",
    "    actions = [item for sublist in actions for item in sublist]\n",
    "    actions = np.array(actions)    \n",
    " \n",
    "    return obs, actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(batch, average, best):\n",
    "    \"\"\"Line plot of average and best rewards over time\"\"\"\n",
    "    \n",
    "    plt.plot(batch, average, label='Average batch reward')\n",
    "    plt.plot(batch, best, label='Best batch reward')\n",
    "    plt.xlabel('Batch')\n",
    "    plt.ylabel('Reward')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main program\n",
    "\n",
    "The main program:\n",
    "\n",
    "* Sets up model\n",
    "* Continues a loop of playing batches and episodes and training net until goal achieved.\n",
    "    * Play batch of episodes\n",
    "    * Select best episodes\n",
    "    * Train neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    ############################## Set up model ################################\n",
    "    \n",
    "    # Set number of episodes to play before slecting best and updating net\n",
    "    episode_batch_size = 10\n",
    "    \n",
    "    # Set up environment\n",
    "    sim = HospGym(sim_duration=SIM_DURATION)\n",
    "    \n",
    "    # Get number of observations from environemt(allows the env to change)\n",
    "    obs_size = sim.observation_size\n",
    "    \n",
    "    # Get number of actins from environemnt\n",
    "    n_actions = sim.action_size\n",
    "    \n",
    "    # Set up Neural Net\n",
    "    model = Net(obs_size, n_actions)\n",
    "    objective = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Play batches of episodes \n",
    "    batch_count = 0\n",
    "    \n",
    "    # Lists to store results\n",
    "    all_results_batch_number = []\n",
    "    all_results_average_reward = []\n",
    "    all_results_maxumum_reward = []\n",
    "    \n",
    "    # Start playing loop and continue until goal performance reached\n",
    "    while True:\n",
    "        \n",
    "        ############## Play batch of epsiodes and select best ##################\n",
    "        \n",
    "        # Play episodes \n",
    "        batch_count += 1\n",
    "        batch_results = []\n",
    "        for episode in range(episode_batch_size):\n",
    "            results = play_episode(sim, model, obs_size)\n",
    "            batch_results.append(results)\n",
    "            \n",
    "        # Get average and maximum reward\n",
    "        rewards = [episode['episode_reward'] for episode in batch_results]\n",
    "        average_reward = np.mean(rewards)\n",
    "        maximum_reward = np.max(rewards)\n",
    "        \n",
    "        # Store results\n",
    "        all_results_batch_number.append(batch_count)\n",
    "        all_results_average_reward.append(average_reward)\n",
    "        all_results_maxumum_reward.append(maximum_reward)\n",
    "        \n",
    "        print (f'\\rBatch {batch_count:3}. Average and best run: ' \\\n",
    "               f'{average_reward:3.1f}, {maximum_reward:3.1f}', end=\"\")\n",
    "        \n",
    "        # Check whether goal reached (and break loop)\n",
    "        if batch_count >= TRAINING_EPISODES:\n",
    "            break\n",
    "        \n",
    "        # Get best runs\n",
    "        training_obs, training_actions = filter_episodes(batch_results)  \n",
    "        training_obs = torch.Tensor(training_obs)\n",
    "        training_actions = torch.Tensor(training_actions).long()\n",
    "        \n",
    "        ########################### Train model ################################\n",
    "        \n",
    "        # Reset model gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Predict actions\n",
    "        action_scores = model(training_obs)\n",
    "        # Calculate loss between predicted and actual actions\n",
    "        loss_v = objective(action_scores, training_actions)\n",
    "        # Back propgate losses\n",
    "        loss_v.backward()\n",
    "        # Update model weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    # Plot results\n",
    "    plot_results(all_results_batch_number, all_results_average_reward, \n",
    "                 all_results_maxumum_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  25. Average and best run: -18402.4, -17645.0.0"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
