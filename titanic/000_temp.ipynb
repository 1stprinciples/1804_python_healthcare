{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic survival - logistic regression model\n",
    "\n",
    "This is an introduction to machine learning classification. Much more training is available at:\n",
    "\n",
    "https://pythonhealthcare.org/titanic-survival/\n",
    "\n",
    "Can we predict which passengers would survive the sinking of the Titanic?\n",
    "\n",
    "See:\n",
    "\n",
    "https://www.kaggle.com/c/titanic/overview/evaluation\n",
    "\n",
    "https://gitlab.com/michaelallen1966/1908_coding_club_kaggle_titanic\n",
    "\n",
    "The original data comes from:\n",
    "\n",
    "https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "Though we will download and use a data set that has been pre-processed ready for machine learning.\n",
    "\n",
    "The data includes:\n",
    "\n",
    "Variable  | Definition\n",
    "----------|-----------\n",
    "survival  | Survival (0 = No, 1 = Yes)\n",
    "pclass    | Ticket class\n",
    "sex       | Sex\n",
    "Age       | Age in years\n",
    "sibsp     | # of siblings / spouses aboard the Titanic\n",
    "parch     | # of parents / children aboard the Titanic\n",
    "ticket    | Ticket number\n",
    "fare      | Passenger fare\n",
    "cabin     | Cabin number\n",
    "embarked  | Port of Embarkation(C=Cherbourg, Q=Queenstown, S=Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "In this example we will use logistic regression (see https://en.wikipedia.org/wiki/Logistic_regression).\n",
    "\n",
    "For an introductory video on logistic regression see: https://www.youtube.com/watch?v=yIYKR4sgzI8\n",
    "\n",
    "Logistic regression takes a range of features (which we will normalise/standardise to put on the same scale) and returns a probability that a certain classification (survival in this case) is true.\n",
    "\n",
    "We will go through the following steps:\n",
    "\n",
    "* Download and save pre-processed data\n",
    "* Split data into features (X) and label (y)\n",
    "* Split data into training and test sets (we will test on data that has not been used to fit the model)\n",
    "* Standardise data\n",
    "* Fit a logistic regression model (from sklearn)\n",
    "* Predict survival of the test set, and assess accuracy\n",
    "* Review model coefficients (weights) to see importance of features\n",
    "* Show probability of survival for passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules\n",
    "\n",
    "A standard Anaconda install of Python (https://www.anaconda.com/distribution/) contains all the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import machine learning methods\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data if required\n",
    "\n",
    "The section below downloads pre-processed data, and saves it to a subfolder (from where this code is run).\n",
    "If data has already been downloaded that cell may be skipped.\n",
    "\n",
    "Code that was used to pre-process the data ready for machine learning may be found at:\n",
    "\n",
    "https://github.com/MichaelAllen1966/1804_python_healthcare/blob/master/titanic/01_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    \"\"\"Download data from web\"\"\"\n",
    "    \n",
    "    address = 'https://raw.githubusercontent.com/MichaelAllen1966/' + \\\n",
    "                '1804_python_healthcare/master/titanic/data/processed_data.csv'\n",
    "    \n",
    "    df = pd.read_csv(address)\n",
    "\n",
    "    # Create a data subfolder if one does not already exist\n",
    "    import os\n",
    "    data_directory ='./data/'\n",
    "    if not os.path.exists(data_directory):\n",
    "        os.makedirs(data_directory)\n",
    "\n",
    "    # Save data\n",
    "    df.to_csv(data_directory + 'processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load data from csv into Pandas dataframe, and cast all data to float\"\"\"\n",
    "    data = pd.read_csv('data/processed_data.csv')\n",
    "    # Make all data 'float' type\n",
    "    data = data.astype(float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine loaded data\n",
    "\n",
    "The data is in the form of a Pandas DataFrame, so we have column headers providing information of what is contained in each column.\n",
    "\n",
    "We will use the DataFrame `.head()` method to show the first few rows of the imported DataFrame. By default this shows the first 5 rows. Here we will look at the first 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also show a summary of the data with the `.describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is a passenger index number. We will remove this, as this is not part of the original Titanic passenger data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_passenger_id(df):\n",
    "    \"\"\"\n",
    "    Takes a pandas dataframe (df)\n",
    "    Drop passenger ID as it is not original data.\"\n",
    "    inplace means to make change in table directly.\n",
    "    axis=1 shows we are remocing a column (axis=0 would be row).\n",
    "    Function returns uncganged datadrame if PassengerId does not exist\n",
    "    \n",
    "    \"\"\"\n",
    "    if 'PassengerId' in list(df):\n",
    "        df.drop('PassengerId', inplace=True, axis=1)\n",
    "        return df\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = drop_passenger_id(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at a summary of passengers who survived or did not survive\n",
    "\n",
    "Before running machine learning models, it is always good to have a look at your data. Here we will separate passengers who survived from those who died, and we will have a look at differences in features.\n",
    "\n",
    "We will use a *mask* to select and filter passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data['Survived'] == 1 # Mask for passengers who survive\n",
    "survived = data[mask] # filter using mask\n",
    "\n",
    "mask = data['Survived'] == 0 # Mask for passengers who died\n",
    "died = data[mask] # filter using mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at average (mean) values for `survived` and `died`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "died.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make looking at them side by side more easy by putting these values in a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame() # New empty DataFrame\n",
    "summary['survived'] = survived.mean()\n",
    "summary['died'] = died.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at them side by side. See if you can spot what features you think might have influenced survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into X (features) and y (labels)\n",
    "\n",
    "We will separate out our features (the data we use to make a prediction) from our label (what we are truing to predict).\n",
    "By convention our features are called `X` (usually upper case to denote multiple features), and the label (survived or not) `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_label(df):\n",
    "    \"\"\"\n",
    "    Produces features by dropping survived column.\n",
    "    Produces labels by retuening just the survived column\n",
    "    \"\"\"\n",
    "    X = df.drop('Survived',axis=1)\n",
    "    y = df['Survived']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_features_and_label(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into training and tets sets\n",
    "\n",
    "When we test a machine learning model we should always test it on data that has not been used to train the model.\n",
    "We will use sklearn's `train_test_split` method to randomly split the data: 75% for training, and 25% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_and_test_sets(X, y):\n",
    "    \"\"\"\n",
    "    Use sklearn's train_test_split to randomly split data.\n",
    "    75% training, 25% test\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_training_and_test_sets(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardise data\n",
    "\n",
    "We want all of out features to be on roughly the same scale. This generally leads to a better model, and also allows us to more easily compare the importance of different features.\n",
    "\n",
    "One simple method is to scale all features 0-1 (by subtracting the minimum value for each value, and dividing by the new remaining maximum value).\n",
    "\n",
    "But a more common method used in many machine learning methods is standardisation, where we use the mean and standard deviation of the training set of data to normalise the data. We subtract the mean of the test set values, and divide by the standard deviation of the training data. Note that the mean and standard deviation of the training data are used to standardise the test set data as well.\n",
    "\n",
    "Here we will use sklearn's `StandardScaler method`. This method also copes with problems we might otherwise have (such as if one feature has zero standard deviation in the training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardise data, by subtracting the feature mean, and dividing by\n",
    "    the feature standard deviation. \n",
    "    \n",
    "    Uses sklearn's StandardScalar\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc = StandardScaler() \n",
    "\n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    # Apply the scaler to the training and test sets\n",
    "    train_std=sc.transform(X_train)\n",
    "    test_std=sc.transform(X_test)\n",
    "    \n",
    "    return train_std, test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std, X_test_std = standardise_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function to calculate accuracy, sensitivity and specificity\n",
    "\n",
    "* *Sensitivity*: the proportion of positive label (survivors) currectly identified (also called recall)\n",
    "* *Specificity*: the proportion of negative label (non-survivors) currectly identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(observed, predicted):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates accuracy, sensitivity, and specificity.\n",
    "    Returns a dictionary of results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Converts list to NumPy arrays (if needed)\n",
    "    if type(observed) == list:\n",
    "        observed = np.array(observed)\n",
    "    if type(predicted) == list:\n",
    "        predicted = np.array(predicted)\n",
    "        \n",
    "    # calculate simple accuracy\n",
    "    accuracy = np.mean(observed == predicted)\n",
    "    \n",
    "    # Split into observed and predicted negatives and positives\n",
    "    observed_positives = observed == 1\n",
    "    observed_negatives = observed == 0\n",
    "    predicted_positives = predicted == 1\n",
    "    predicted_negatives = predicted == 0\n",
    "    \n",
    "    # Calculate true and false positive/negatives\n",
    "    # We calaculate mroe than we need here, but they are useful to put here\n",
    "    true_positives = (predicted_positives == 1) & (observed_positives == 1)\n",
    "    false_positives = (predicted_positives == 1) & (observed_positives == 0)\n",
    "    true_negatives = (predicted_negatives == 1) & (observed_negatives == 1)\n",
    "    false_negatives = (predicted_negatives == 1) & (observed_negatives == 0)\n",
    "    \n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = np.sum(true_positives) / np.sum(observed_positives)\n",
    "    specificity = np.sum(true_negatives) / np.sum(observed_negatives)\n",
    "    \n",
    "    # Put results in a dictionary (keyword and value)    \n",
    "    results = {'accuracy': accuracy,\n",
    "               'sensitivity': sensitivity,\n",
    "               'specificity': specificity}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit logistic regression model\n",
    "\n",
    "Now we will fit a logistic regression model, using sklearn's `LogisticRegression` method. Our machine learning model fitting is only two lines of code!\n",
    "By using the name `model` for our logistic regression model we will make our model more interchangeable later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lr_model(X_train_std,y_train):\n",
    "    \"\"\"Set up sklearn logistic regression model and train\"\"\"\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train_std,y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_lr_model(X_train_std,y_train)\n",
    "# Show model\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict values\n",
    "\n",
    "Now we can use the trained model to predict survival. We will test the accuracy of both the training and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_categories(model, X):\n",
    "    \"\"\"Predict label categories, given features X\"\"\"\n",
    "\n",
    "    return model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = predict_categories(model, X_train_std)\n",
    "y_pred_test = predict_categories(model, X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = calculate_accuracy(y_test, y_pred_test)\n",
    "\n",
    "# print results using python print format to round decimal places\n",
    "\n",
    "print ('Accuracy: {0:0.2f}'.format(results['accuracy']))\n",
    "print ('Sensitivity: {0:0.2f}'.format(results['sensitivity']))\n",
    "print ('Specificity: {0:0.2f}'.format(results['specificity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the model coefficients (weights)\n",
    "\n",
    "Not all features are equally important. And some may be of little or no use at all, unnecessarily increasing the complexity of the model. In a later notebook we will look at selecting features which add value to the model (or removing features that don’t).\n",
    "\n",
    "Here we will look at the importance of features – how they affect our estimation of survival. These are known as the model *coefficients* (if you come from a traditional statistics background), or model *weights* (if you come from a machine learning background). \n",
    "\n",
    "Because we have standardised our input data the magnitude of the weights may be compared as an indicator of their influence in the model. Weights with higher negative numbers mean that that feature correlates with reduced chance of survival. Weights with higher positive numbers mean that that feature correlates with increased chance of survival. Those weights with values closer to zero (either positive or negative) have less influence in the model.\n",
    "\n",
    "We access the model weights my examining the model `coef_` attribute. The model may predict more than one outcome label, in which case we have weights for each label. Because we are predicting a signle label (survive or not), the weights are found in the first element (`[0]`) of the `coef_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have an array of model weights.\n",
    "\n",
    "Not very readable for us mere humans is it?!\n",
    "\n",
    "We will write a function to transfer the weights array to a Pandas DataFrame. The array order is in the same order of the list of features of X, so we will put that those into the DataFrame as well. And we will sort by influence in the model. Because both large negative and positive values are more influential in the model we will take the *absolute* value of the weight (that is remove any negative sign), and then sort by that absolute value. That will give us a more readable table of most influential features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_weights(model, X):\n",
    "    \"\"\"Returns a sorted dataframe of model weights. Assumes a single class.\n",
    "    Takes model and X dataframe\"\"\"\n",
    "    \n",
    "    co_eff_df = pd.DataFrame() # create empty DataFrame\n",
    "    \n",
    "    # Get list of features\n",
    "    co_eff_df['feature'] = list(X) # Get feature names from X\n",
    "    \n",
    "    # Get weights (for one class)\n",
    "    co_eff_df['co_eff'] = model.coef_[0]\n",
    "    \n",
    "    # Get absolute value of weight and sort by absolute value\n",
    "    co_eff_df['abs_co_eff'] = np.abs(co_eff_df['co_eff'])\n",
    "    co_eff_df.sort_values(by='abs_co_eff', ascending=False, inplace=True)\n",
    "\n",
    "    return co_eff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = get_model_weights(model, X)\n",
    "print (model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show predicted probabilities\n",
    "\n",
    "The predicted probabilities are for the two alternative classes 0 (does not survive) or 1 (survive).\n",
    "\n",
    "Ordinarily we do not see these probabilities - the `predict` method used above applies a cut-off of 0.5 to classify passengers into survived or not, but we can see the individual probabilities for each passenger.\n",
    "\n",
    "Later we will use these to adjust sensitivity of our model to detecting survivors or non-survivors.\n",
    "\n",
    "Each passenger has two values. These are the probability of not surviving (first value) or surviving (second value). Because we only have two possible classes we only need to look at one. Multiple values are important when there are more than one class being predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(X_test_std)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrapi it in a function and show just the probability of the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probabilities(model, X):\n",
    "    \"\"\"Predict label categories, given features X\"\"\"\n",
    "    \n",
    "    probabilities = model.predict_proba(X)\n",
    "    prob_of_positive_class = probabilities[:,1]\n",
    "\n",
    "    return prob_of_positive_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first ten predicted probabilities \n",
    "# (note how the values relate to the classes predicted above)\n",
    "probabilities = predict_probabilities(model, X_test_std)\n",
    "probabilities[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare this to the standard classification, we'll see that everything with a probability over 0.5 will be classed as positive.\n",
    "\n",
    "We'll put it in a dataframe to comapre more easily by eye:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first ten predicted classes\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['probabilty'] = predict_probabilities(model, X_test_std)\n",
    "df['class'] = predict_categories(model, X_test_std)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the number of postive classes using the standard classification method is the same as the number of cases that have a probability of >= 0.5 (the print formating prints with zero decimal places)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Number of positives: {0:.0f}'.format(np.sum(df['class']==1)))\n",
    "print ('Number of prob >= 0.5: {0:.0f}'.format(np.sum(df['probabilty']>=0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing classification threshold\n",
    "\n",
    "We can use the model probability output to change the sensitivity of the model. Reducing the threshold will increase the sensitivity of the model (the ability to detect positives), but will reduce the specificity of the model (he ability to detect negatives). Depending on which is most important (the ability to identify positive cases, or the importance in not misclassifying negative cases), we can fine-tune our model in the way we wish.\n",
    "\n",
    "Let us put classification with a given threshold into a function. We will seta default threshold of 0.5 so our function will beahve like a normal classifyer if no adjusted threshold is passed to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_with_threshold(model, X, threshold=0.5):\n",
    "    \"\"\"Predict label categories, given features X, and an optional threshold \"\"\"\n",
    "    \n",
    "    probabilities = model.predict_proba(X)\n",
    "    positives = probabilities[:,1] >= threshold\n",
    "    \n",
    "    return positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets' test it at a couple of thresholds (default, and a reduce threshold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = classify_with_threshold(model, X_test_std)\n",
    "\n",
    "results = calculate_accuracy(y_test, y_pred_test)\n",
    "\n",
    "# print results using python print format to round decimal places\n",
    "\n",
    "print ('Accuracy: {0:0.2f}'.format(results['accuracy']))\n",
    "print ('Sensitivity: {0:0.2f}'.format(results['sensitivity']))\n",
    "print ('Specificity: {0:0.2f}'.format(results['specificity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = classify_with_threshold(model, X_test_std, threshold=0.2)\n",
    "\n",
    "results = calculate_accuracy(y_test, y_pred_test)\n",
    "\n",
    "# print results using python print format to round decimal places\n",
    "\n",
    "print ('Accuracy: {0:0.2f}'.format(results['accuracy']))\n",
    "print ('Sensitivity: {0:0.2f}'.format(results['sensitivity']))\n",
    "print ('Specificity: {0:0.2f}'.format(results['specificity']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "We've defined a lot of re-usable functions. This allows us to put together compact code for the whole pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "data = drop_passenger_id(data)\n",
    "X, y = get_features_and_label(data)\n",
    "X_train_std, X_test_std = standardise_data(X_train, X_test)\n",
    "model = build_lr_model(X_train_std,y_train)\n",
    "threshold = 0.5\n",
    "y_pred_test = classify_with_threshold(model, X_test_std, threshold=threshold)\n",
    "results = calculate_accuracy(y_test, y_pred_test)\n",
    "\n",
    "# print results using python print format to round decimal places\n",
    "\n",
    "print ('Accuracy: {0:0.2f}'.format(results['accuracy']))\n",
    "print ('Sensitivity: {0:0.2f}'.format(results['sensitivity']))\n",
    "print ('Specificity: {0:0.2f}'.format(results['specificity']))\n",
    "\n",
    "# Print first 10 classifications\n",
    "print('\\nFirst 10 classifications of test set:')\n",
    "print(y_pred_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "\n",
    "Using the functions we have defined, create a chart of how accuracy, sensitivity and specificity change with varying thresholds.\n",
    "\n",
    "You can reveal the answer below (you may have done it a different way)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reveal answer using the small dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split data\n",
    "data = load_data()\n",
    "data = drop_passenger_id(data)\n",
    "X, y = get_features_and_label(data)\n",
    "\n",
    "# Standardise data\n",
    "X_train_std, X_test_std = standardise_data(X_train, X_test)\n",
    "\n",
    "# Build model\n",
    "model = build_lr_model(X_train_std,y_train)\n",
    "\n",
    "# Loop through a list of thresholds\n",
    "thresholds = np.arange(0, 1.01, 0.05)\n",
    "results_accuracy = []\n",
    "results_sensitivity = []\n",
    "results_specificity = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Classify using threshold\n",
    "    y_pred_test = classify_with_threshold(\n",
    "        model, X_test_std, threshold=threshold)\n",
    "    \n",
    "    # Get results and append to lists\n",
    "    results = calculate_accuracy(y_test, y_pred_test)\n",
    "    results_accuracy.append(results['accuracy'])\n",
    "    results_sensitivity.append(results['sensitivity'])\n",
    "    results_specificity.append(results['specificity'])\n",
    "    \n",
    "# Define a plot function\n",
    "def plot_results(thresholds, accuracy, sensitivity, specificity):\n",
    "    \"\"\"Create line plot of the relationship between classification threshold and\n",
    "    accuracy, sensitivity, and specificity\"\"\"\n",
    "    \n",
    "    plt.plot(thresholds, accuracy, label='accuracy', marker='s')\n",
    "    plt.plot(thresholds, sensitivity, label='sensitivity', marker='o')\n",
    "    plt.plot(thresholds, specificity, label='specificity', marker='^')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('Result')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Call plot function    \n",
    "plot_results(thresholds, results_accuracy, results_sensitivity, \n",
    "             results_specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
