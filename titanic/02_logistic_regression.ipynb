{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic survival - logistic regression model\n",
    "\n",
    "Can we predict which passengers would survive the sinking of the Titanic?\n",
    "\n",
    "See:\n",
    "\n",
    "https://www.kaggle.com/c/titanic/overview/evaluation\n",
    "\n",
    "https://gitlab.com/michaelallen1966/1908_coding_club_kaggle_titanic\n",
    "\n",
    "The data comes from:\n",
    "\n",
    "https://www.kaggle.com/c/titanic/data\n",
    "\n",
    "And the data includes:\n",
    "\n",
    "Variable  | Definition\n",
    "----------|-----------\n",
    "survival  | Survival (0 = No, 1 = Yes)\n",
    "pclass    | Ticket class\n",
    "sex       | Sex\n",
    "Age       | Age in years\n",
    "sibsp     | # of siblings / spouses aboard the Titanic\n",
    "parch     | # of parents / children aboard the Titanic\n",
    "ticket    | Ticket number\n",
    "fare      | Passenger fare\n",
    "cabin     | Cabin number\n",
    "embarked  | Port of Embarkation(C=Cherbourg, Q=Queenstown, S=Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Passengerid (axis=1 indicates we are removing a column rather than a row)\n",
    "\n",
    "data.drop('PassengerId', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into X (features) and y (lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Survived',axis=1)\n",
    "y = data['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide into training and tets sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardise data\n",
    "\n",
    "We want all of out features to be on roughly the same scale.\n",
    "\n",
    "We will use standardisation. Where we use the mean and standard deviation of the training set of data to standardise the data. We substract the mean of the test set values, and dividie by the standard deviation of the training data. Note that the mean and standard deviation of the training data are used to standardise the test set data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_data(X_train, X_test):\n",
    "    \n",
    "    # Initialise a new scaling object for normalising input data\n",
    "    sc=StandardScaler() \n",
    "\n",
    "    # Set up the scaler just on the training set\n",
    "    sc.fit(X_train)\n",
    "\n",
    "    # Apply the scaler to the training and test sets\n",
    "    train_std=sc.transform(X_train)\n",
    "    test_std=sc.transform(X_test)\n",
    "    \n",
    "    return train_std, test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_std, X_test_std = standardise_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict training and test set labels\n",
    "y_pred_train = model.predict(X_train_std)\n",
    "y_pred_test = model.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = np.mean(y_pred_train == y_train)\n",
    "accuracy_test = np.mean(y_pred_test == y_test)\n",
    "\n",
    "print ('Accuracy of predicting training data =', accuracy_train)\n",
    "print ('Accuracy of predicting test data =', accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the model coefficients (weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_eff = model.coef_[0]\n",
    "co_eff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put in a DataFrame and sort by coefficient size.\n",
    "\n",
    "This might be used to select top features (and refit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_eff_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_eff_df['feature'] = list(X)\n",
    "co_eff_df['co_eff'] = co_eff\n",
    "co_eff_df['abs_co_eff'] = np.abs(co_eff)\n",
    "co_eff_df.sort_values(by='abs_co_eff', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_eff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show predicted probabilities\n",
    "\n",
    "The predicted probabilities are for the two alternative classes 0 (does not survive) or 1 (survive).\n",
    "\n",
    "Later we will use these to adjust sensitivity of our model to detecting survivors or non-survivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict_proba(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first five values\n",
    "probabilities[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
